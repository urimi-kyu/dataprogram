import urllib.request
import json
import datetime
import numpy as np
import sys
import urllib.parse
import mdd_predictor  # ğŸ‘ˆ mdd_predictor.py ì„í¬íŠ¸

# --- 1. Naver API ë° ìƒìˆ˜ ---

# (ì¤‘ìš”!) Naver API ì¸ì¦ ì •ë³´ (âš ï¸ ì‹¤ì œ ê°’ìœ¼ë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤.)
CLIENT_ID = "xAkr8e4sWLnQW4x_YnIh"
CLIENT_SECRET = "gkDg6FlbBR"

# ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” 8ê°œ ì¬ë‚œ í‚¤ì›Œë“œ ìˆœì„œ (ëª¨ë¸ ì…ë ¥ ì°¨ì› 8ê³¼ ì¼ì¹˜)
MODEL_INPUT_ORDER = [
    "ì‚°ë¶ˆ", "ì§€ì§„", "íƒœí’", "ê°ì—¼ë³‘", "ê°€ë­„", "í­ì„¤", "í™ìˆ˜", "ê¸°íƒ€"
]
# í¬ë¡¤ë§ ì‹œ í™ìˆ˜ì™€ í•¨ê»˜ ì²´í¬í•  í‚¤ì›Œë“œ
DISASTERS_TO_CHECK = MODEL_INPUT_ORDER + ["í­ìš°"]

# ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” 12ê°œ ì„¹í„° ì´ë¦„ (MDD ì˜ˆì¸¡ ì¶œë ¥ ì°¨ì› 12ì™€ ì¼ì¹˜)
SECTORS = [
    "ì½”ìŠ¤í”¼ ì „ì²´ ì‹œì¥",            # Market (KOSPI)
    "ì½”ìŠ¤í”¼200 í†µì‹ ì„œë¹„ìŠ¤",        # Communication Services
    "ì½”ìŠ¤í”¼200 ê±´ì„¤",              # Construction
    "ì½”ìŠ¤í”¼200 ì¤‘ê³µì—…",            # Heavy Industry
    "ì½”ìŠ¤í”¼200 ì² ê°•Â·ì†Œì¬",         # Steel/Materials
    "ì½”ìŠ¤í”¼200 ì—ë„ˆì§€Â·í™”í•™",       # Energy/Chemicals
    "ì½”ìŠ¤í”¼200 ì •ë³´ê¸°ìˆ ",          # Information Technology
    "ì½”ìŠ¤í”¼200 ê¸ˆìœµ",              # Finance
    "ì½”ìŠ¤í”¼200 í•„ìˆ˜ì†Œë¹„ì¬",        # Consumer Staples
    "ì½”ìŠ¤í”¼200 ììœ ì†Œë¹„ì¬",        # Consumer Discretionary
    "ì½”ìŠ¤í”¼200 ì‚°ì—…ì¬",            # Industrials
    "ì½”ìŠ¤í”¼200 í—¬ìŠ¤ì¼€ì–´"           # Healthcare
]

# FE ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
def fetch_disaster_news(keyword, max_results=3):
    """íŠ¹ì • ì¬ë‚œ í‚¤ì›Œë“œì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸(title, link) ë°˜í™˜"""
    TODAY_DATE_STR = datetime.date.today().strftime("%Y%m%d")

    encText = urllib.parse.quote(f"{keyword} ì¬ë‚œ í”¼í•´")

    url = (
        f"https://openapi.naver.com/v1/search/news.json?query={encText}"
        f"&display={max_results}&sort=sim&start=1"
        f"&enddate={TODAY_DATE_STR}&startdate={TODAY_DATE_STR}"
    )

    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", CLIENT_ID)
    request.add_header("X-Naver-Client-Secret", CLIENT_SECRET)

    try:
        response = urllib.request.urlopen(request)
        rescode = response.getcode()

        if rescode != 200:
            return []

        response_body = response.read()
        result = json.loads(response_body.decode('utf-8'))

        items = result.get("items", [])
        news_list = []
        for item in items:
            news_list.append({
                "title": item.get("title", ""),
                "link": item.get("link", ""),
                "description": item.get("description", "")
            })
        return news_list

    except Exception:
        return []

def get_today_disaster_news_grouped(max_results=3):
    """MODEL_INPUT_ORDER ê¸°ì¤€ 8ê°œ ì¬ë‚œë³„ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    grouped = {}
    for disaster in MODEL_INPUT_ORDER:
        grouped[disaster] = fetch_disaster_news(disaster, max_results=max_results)
    return grouped
# FE END

# --- 2. ë‰´ìŠ¤ í¬ë¡¤ë§ ë° ë²¡í„° ë³€í™˜ í•¨ìˆ˜ ---


def search_disaster_occurrence_news(keyword):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¥¼ í˜¸ì¶œí•˜ì—¬ íŠ¹ì • í‚¤ì›Œë“œì˜ ì˜¤ëŠ˜ ë‰´ìŠ¤ ê±´ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    TODAY_DATE_STR = datetime.date.today().strftime("%Y%m%d")

    encText = urllib.parse.quote(f"'{keyword}' AND (ì†ë³´ OR ë°œìƒ OR í”¼í•´)")

    url = (f"https://openapi.naver.com/v1/search/news.json?query={encText}"
           f"&display=100&sort=sim&start=1&enddate={TODAY_DATE_STR}&startdate={TODAY_DATE_STR}")

    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", CLIENT_ID)
    request.add_header("X-Naver-Client-Secret", CLIENT_SECRET)

    try:
        response = urllib.request.urlopen(request)
        rescode = response.getcode()

        if rescode == 200:
            response_body = response.read()
            result = json.loads(response_body.decode('utf-8'))
            return result.get('total', 0)
        else:
            print(f"âŒ [{keyword}] API Error Code: {rescode}", file=sys.stderr)
            return 0
    except urllib.error.URLError as e:
        print(f"âŒ [{keyword}] URL Error: {e.reason}. ì¸ì¦ ì •ë³´ í™•ì¸ í•„ìš”.",
              file=sys.stderr)
        return 0
    except Exception as e:
        print(f"âŒ [{keyword}] Unknown Error: {e}", file=sys.stderr)
        return 0


def convert_counts_to_vector(disaster_counts: dict) -> list:
    """í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê±´ìˆ˜ë¥¼ ëª¨ë¸ ì…ë ¥ ë²¡í„°(8ì°¨ì›)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    vector = []

    # 'í™ìˆ˜' ë° 'í­ìš°' ì¹´ìš´íŠ¸ë¥¼ í•©ì‚°
    flood_count = disaster_counts.get("í™ìˆ˜", 0) + disaster_counts.get("í­ìš°", 0)

    # MODEL_INPUT_ORDER ìˆœì„œì— ë§ì¶° ë²¡í„° ìƒì„±
    for disaster in MODEL_INPUT_ORDER:
        if disaster == "í™ìˆ˜":
            count = flood_count
        else:
            count = disaster_counts.get(disaster, 0)

        # ì •ê·œí™” (ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì •ê·œí™” ë°©ì‹ê³¼ ì¼ì¹˜í•´ì•¼ í•¨)
        intensity = min(1.0, count / 100.0)
        vector.append(intensity)

    return vector


# --- 3. ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í•¨ìˆ˜ (app.pyê°€ í˜¸ì¶œ) ---

def get_today_mdd_prediction(main_keyword):
    """ì˜¤ëŠ˜ ë‚ ì§œì˜ ë‰´ìŠ¤ ê°•ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ MDD ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    # 1. ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
    disaster_counts = {}
    for disaster in DISASTERS_TO_CHECK:
        count = search_disaster_occurrence_news(disaster)
        disaster_counts[disaster] = count

    # 2. í¬ë¡¤ë§ ê²°ê³¼ë¥¼ AI ëª¨ë¸ ì…ë ¥ ë²¡í„°(ì ìˆ˜)ë¡œ ë³€í™˜
    disaster_vector_list = convert_counts_to_vector(disaster_counts)

    # ëª¨ë¸ ì…ë ¥ í˜•íƒœ: (1, 8) numpy.float32
    feature_vector = np.array(disaster_vector_list).reshape(
        1, mdd_predictor.INPUT_DIM).astype(np.float32)

    # 3. AI ëª¨ë¸ í˜¸ì¶œí•˜ì—¬ MDD ì˜ˆì¸¡
    try:
        mdd_predictions_vector = mdd_predictor.predict_mdd_value(
            feature_vector)
    except RuntimeError as e:
        return {'error': f"MDD ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰ ì‹¤íŒ¨: {e}"}

    # 4. ìµœì¢… ê²°ê³¼ ì •ë¦¬
    if mdd_predictions_vector is None or len(mdd_predictions_vector) != len(SECTORS):
        return {'error': "MDD ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ì˜ ì°¨ì›ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."}

    # ê°€ì¥ ë†’ì€ MDD ê°’ê³¼ ê·¸ ì„¹í„°ë¥¼ ì°¾ìŒ (ìµœì•…ì˜ ì‹œë‚˜ë¦¬ì˜¤)
    max_mdd_index = np.argmax(mdd_predictions_vector)
    max_mdd_value = mdd_predictions_vector[max_mdd_index]
    max_mdd_sector = SECTORS[max_mdd_index]

    # ìƒì„¸ ê²°ê³¼ ë¬¸ìì—´ êµ¬ì„±
    detail_results = [
        f"{SECTORS[i]}: {mdd_predictions_vector[i]:.2f}%" for i in range(len(SECTORS))]
    detail_text = "ì „ ì„¹í„° ì˜ˆì¸¡ MDD: " + ", ".join(detail_results)
    
    # ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ê°€ê³µ
    sector_data = []
    for i, sector_name in enumerate(SECTORS):
        value = mdd_predictions_vector[i]
        sector_data.append({
            'name': sector_name,
            'value': float(value)
        })

    # ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡í–ˆë‹¤ê³  í‘œì‹œ
    event_date_str = datetime.date.today().strftime("%Y-%m-%d")

    return {
        'status': 'success',
        'event_name': main_keyword,
        'event_date': event_date_str,
        'predicted_mdd': f"{max_mdd_value:.2f}% ({max_mdd_sector})",
        'detail': detail_text,
        'sector_data': sector_data
    }
