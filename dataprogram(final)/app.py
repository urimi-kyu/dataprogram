import pandas as pd
import numpy as np
from pykrx import stock
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
import os
from flask import Flask, render_template, request, jsonify
from io import BytesIO
import base64
from urllib.parse import unquote
import sys
import mdd_prediction_service  # ğŸ“Œ MDD ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸

# ---------------------------------------------------
plt.switch_backend('Agg')
# ---------------------------------------------------

# --- Flask ì•± ì´ˆê¸°í™” ---
app = Flask(__name__)

# --- ì„¤ì •ê°’ ë° ìƒìˆ˜ ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DISASTER_CSV_PATH = os.path.join(BASE_DIR, 'event.csv')
ANALYSIS_MONTHS_BEFORE = 3
ANALYSIS_MONTHS_AFTER = 3

# KOSPI 200 Big Sector Index Codes (ì´ 12ê°œ)
SECTOR_CODES = {
    'Market (KOSPI)': '1001',
    'KOSPI 200 - Communication Services': '1150',
    'KOSPI 200 - Construction': '1151',
    'KOSPI 200 - Heavy Industry': '1152',
    'KOSPI 200 - Steel/Materials': '1153',
    'KOSPI 200 - Energy/Chemicals': '1154',
    'KOSPI 200 - Information Technology': '1155',
    'KOSPI 200 - Finance': '1156',
    'KOSPI 200 - Consumer Staples': '1157',
    'KOSPI 200 - Consumer Discretionary': '1158',
    'KOSPI 200 - Industrials': '1159',
    'KOSPI 200 - Healthcare': '1160'
}

# --- 1. ë¶„ì„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ---


def analyze_sector_performance(close_prices: pd.Series) -> dict:
    """ì£¼ê°€ ë°ì´í„°(ì¢…ê°€ Series)ë¥¼ ë°›ì•„ MDD, ìµœì¢… ì¦ê°ë¥ , Final Drawdownì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    rolling_max = close_prices.expanding().max()
    drawdown = (close_prices / rolling_max) - 1
    mdd_value = round(drawdown.min() * -1 * 100, 2)
    cumulative_return = (close_prices.iloc[-1] / close_prices.iloc[0]) - 1
    cumulative_return_pct = round(cumulative_return * 100, 2)
    final_dd_pct = round(drawdown.iloc[-1] * 100, 2)

    return {
        'MDD (%)': mdd_value,
        'Final Return (%)': cumulative_return_pct,
        'Final DD (%)': final_dd_pct,
        'drawdown_series': drawdown
    }


# --- 2. CSV íŒŒì¼ ë¡œë“œ ë° ê²€ìƒ‰ í•¨ìˆ˜ ---
EXPECTED_COLUMNS = ['EventName', 'EventDate', 'EventType']


def load_csv_with_encoding_fallback():
    """ì—¬ëŸ¬ ì¸ì½”ë”©ì„ ì‹œë„í•˜ê³ , ì‹¤íŒ¨ ì‹œ í—¤ë”ë¥¼ ìˆ˜ë™ ë³µêµ¬í•˜ì—¬ DataFrameì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    df_disaster = None

    for encoding in ['utf-8', 'euc-kr', 'cp949']:
        try:
            df_disaster = pd.read_csv(DISASTER_CSV_PATH, encoding=encoding)
            df_disaster.encoding = encoding
            break
        except Exception:
            continue

    if df_disaster is None:
        raise Exception("CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¸ì½”ë”©ì´ê±°ë‚˜ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")

    if not all(col in df_disaster.columns for col in EXPECTED_COLUMNS):

        try:
            df_disaster_noheader = pd.read_csv(
                DISASTER_CSV_PATH, header=None, encoding=df_disaster.encoding)

            header_row = df_disaster_noheader.iloc[0]
            df_disaster = df_disaster_noheader[1:].copy()
            df_disaster.columns = header_row.tolist()

            if df_disaster.columns.tolist()[:len(EXPECTED_COLUMNS)] != EXPECTED_COLUMNS:
                df_disaster.columns = EXPECTED_COLUMNS + \
                    df_disaster.columns.tolist()[len(EXPECTED_COLUMNS):]

        except Exception as e:
            raise ValueError(
                f"í•„ìˆ˜ ì»¬ëŸ¼ [{', '.join(EXPECTED_COLUMNS)}]ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {df_disaster.columns.tolist()}")

    return df_disaster[EXPECTED_COLUMNS].drop_duplicates()


def get_disaster_types_and_events():
    """CSV íŒŒì¼ì—ì„œ ëª¨ë“  ì¬ë‚œ ì¢…ë¥˜(EventType)ì™€ ì´ë²¤íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    df_disaster = load_csv_with_encoding_fallback()

    disaster_types = sorted(df_disaster['EventType'].unique().tolist())
    events_by_type = df_disaster.groupby('EventType')['EventName'].unique().apply(
        lambda x: sorted(x.tolist())).to_dict()

    return disaster_types, events_by_type


def get_all_disaster_names():
    """CSV íŒŒì¼ì—ì„œ ëª¨ë“  ì¬ë‚œëª…ì„ í‰ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
    df_disaster = load_csv_with_encoding_fallback()

    return df_disaster[['EventName']].drop_duplicates()


def get_event_date_by_name(disaster_name: str) -> str:
    """íŠ¹ì • ì¬ë‚œì˜ ë‚ ì§œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    df_disaster = load_csv_with_encoding_fallback()

    result = df_disaster[df_disaster['EventName'] == disaster_name]
    if result.empty:
        raise ValueError(f"'{disaster_name}'ì— í•´ë‹¹í•˜ëŠ” ì¬ë‚œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    event_datetime_str = result['EventDate'].iloc[0]
    return pd.to_datetime(event_datetime_str).strftime('%Y-%m-%d')


def find_stock_code(corp_name):
    """íšŒì‚¬ ì´ë¦„(ì¢…ëª©ëª…)ìœ¼ë¡œ 6ìë¦¬ ì¢…ëª© ì½”ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        df_list = stock.get_market_ticker_list()
        for ticker in df_list:
            name = stock.get_market_ticker_name(ticker)
            if name == corp_name:
                return ticker
        return None
    except Exception:
        return None

# --- 3. í•µì‹¬ ë¶„ì„ ì‹¤í–‰ ë¡œì§ (ì„¹í„° ì „ì²´) ---


def run_analysis_for_event(event_name):
    """íŠ¹ì • ì¬ë‚œëª…ì— ëŒ€í•œ ì„¹í„° ë¶„ì„ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ DataFrameê³¼ Base64 ì°¨íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""

    try:
        EVENT_DATE_STR = get_event_date_by_name(event_name)
        event_date_dt = pd.to_datetime(EVENT_DATE_STR)

        start_date = (
            event_date_dt - pd.DateOffset(months=ANALYSIS_MONTHS_BEFORE)).strftime('%Y%m%d')
        end_date = (
            event_date_dt + pd.DateOffset(months=ANALYSIS_MONTHS_AFTER)).strftime('%Y%m%d')

    except Exception as e:
        return {'error': str(e)}

    results_list = []
    all_sector_prices = {}
    all_sector_analysis = {}

    for sector_name, code in SECTOR_CODES.items():
        try:
            df_ohlcv = stock.get_index_ohlcv_by_date(
                start_date, end_date, code)

            if df_ohlcv.empty:
                continue

            df_ohlcv.rename(columns={'ì¢…ê°€': 'Close'}, inplace=True)

            analysis = analyze_sector_performance(df_ohlcv['Close'])

            start_price = df_ohlcv['Close'].iloc[0]
            prices_norm = (df_ohlcv['Close'] / start_price) * 100
            all_sector_prices[sector_name] = prices_norm
            all_sector_analysis[sector_name] = {
                'prices': df_ohlcv['Close'], 'mdd_info': analysis}

            results_list.append({
                'Sector Name': sector_name,
                'MDD (%)': analysis['MDD (%)'],
                'Final DD (%)': analysis['Final DD (%)'],
                'Final Return (%)': analysis['Final Return (%)'],
            })

        except Exception:
            continue

    df_results = pd.DataFrame(results_list)

    if df_results.empty:
        return {'error': "ë¶„ì„ ê¸°ê°„ ë™ì•ˆ ìœ íš¨í•œ ì£¼ì‹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    df_results = df_results.sort_values(by='MDD (%)', ascending=False)

    # --- 4. ê·¸ë˜í”„ ìƒì„± ë° Base64 ì¸ì½”ë”© ë¡œì§ ---

    plt.rcParams['font.family'] = 'Arial'
    plt.rcParams['axes.unicode_minus'] = False

    # 4-1. í†µí•© ë¹„êµ ì°¨íŠ¸ ìƒì„± (Base64)
    plt.figure(figsize=(15, 8))
    plt.style.use('seaborn-v0_8-whitegrid')
    for sector_name, prices in all_sector_prices.items():
        plt.plot(prices.index, prices.values, label=sector_name)
    plt.title(
        f'Sector Price Movement Comparison (Normalized: Start=100) \n Event Date: {EVENT_DATE_STR}', fontsize=16)
    plt.xlabel('Date', fontsize=12)
    plt.ylabel('Normalized Stock Index', fontsize=12)
    plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title='Sector')
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))
    plt.gcf().autofmt_xdate()
    plt.axvline(x=event_date_dt, color='red', linestyle='-',
                linewidth=2, label='Event Date')
    plt.axhline(y=100, color='gray', linestyle='--', linewidth=1)
    plt.grid(True)

    buffer = BytesIO()
    plt.savefig(buffer, format='png', bbox_inches='tight')
    plt.close()
    combined_chart_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

    # 4-2. ê°œë³„ ì„¹í„° ì°¨íŠ¸ ìƒì„± (Base64 ë¦¬ìŠ¤íŠ¸)
    individual_charts = []
    for sector_name, analysis_data in all_sector_analysis.items():
        prices_norm = all_sector_prices[sector_name]
        prices_raw = analysis_data['prices']
        full_analysis = analyze_sector_performance(prices_raw)
        mdd_value = full_analysis['MDD (%)']
        drawdown_series = full_analysis['drawdown_series']

        trough_date = drawdown_series.idxmin()
        rolling_max_raw = prices_raw.expanding().max()
        peak_price_raw_at_trough = rolling_max_raw.loc[trough_date]
        potential_peak_dates = rolling_max_raw.index[(rolling_max_raw.index <= trough_date) & (
            rolling_max_raw == peak_price_raw_at_trough)]
        peak_date = potential_peak_dates.max()
        peak_price_norm = prices_norm.loc[peak_date]

        # ì°¨íŠ¸ ê·¸ë¦¬ê¸°
        plt.figure(figsize=(10, 6))
        plt.style.use('seaborn-v0_8-whitegrid')
        plt.plot(prices_norm.index, prices_norm.values,
                 label=sector_name, color='blue')
        plt.scatter(peak_date, peak_price_norm, color='green',
                    marker='o', s=80, label='Peak')
        plt.scatter(trough_date, prices_norm.loc[trough_date],
                    color='red', marker='o', s=80, label='Trough')
        plt.annotate(f'MDD: {mdd_value}%', (trough_date, prices_norm.loc[trough_date]), textcoords="offset points", xytext=(
            0, -20), ha='center', fontsize=11, color='red', bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.6))
        plt.title(
            f'Price Movement: {sector_name} (MDD: {mdd_value}%)', fontsize=14)
        plt.xlabel('Date', fontsize=10)
        plt.ylabel('Normalized Stock Index (Start=100)', fontsize=10)
        plt.axvline(x=event_date_dt, color='gray', linestyle='--',
                    linewidth=1, label='Event Date')
        plt.axhline(y=100, color='gray', linestyle=':', linewidth=1)
        plt.legend(loc='upper left')
        plt.grid(True)

        buffer = BytesIO()
        plt.savefig(buffer, format='png', bbox_inches='tight')
        plt.close()
        individual_charts.append({
            'name': sector_name,
            'base64_img': base64.b64encode(buffer.getvalue()).decode('utf-8')
        })

    # --- 5. ìµœì¢… ë°˜í™˜ ---
    return {
        'df_results': df_results,
        'event_name': event_name,
        'event_date': event_date_dt.strftime('%Y-%m-%d'),
        'start_date': start_date,
        'end_date': end_date,
        'combined_chart': combined_chart_base64,
        'individual_charts': individual_charts
    }

# --- 6. ê°œë³„ ê¸°ì—… ë¶„ì„ ë¡œì§ ---


def analyze_individual_stock(event_name, corp_name, months_before, months_after):
    """ê°œë³„ ì¢…ëª©ì˜ MDDì™€ ì°¨íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""

    try:
        event_date_str = get_event_date_by_name(event_name)
        event_date_dt = pd.to_datetime(event_date_str)

        ticker = find_stock_code(corp_name)

        if not ticker:
            raise ValueError(f"'{corp_name}' ticker not found.")

        start_date = (event_date_dt -
                      pd.DateOffset(months=months_before)).strftime('%Y%m%d')
        end_date = (event_date_dt +
                    pd.DateOffset(months=months_after)).strftime('%Y%m%d')

        df_ohlcv = stock.get_market_ohlcv_by_date(start_date, end_date, ticker)

        if df_ohlcv.empty:
            raise ValueError(
                f"No data available for '{corp_name}' in the period.")

        df_ohlcv.rename(columns={'ì¢…ê°€': 'Close'}, inplace=True)

        analysis = analyze_sector_performance(df_ohlcv['Close'])

        # --- ì°¨íŠ¸ ìƒì„± ë¡œì§ ---
        plt.rcParams['font.family'] = 'Arial'
        plt.rcParams['axes.unicode_minus'] = False

        prices_raw = df_ohlcv['Close']
        prices_norm = (prices_raw / prices_raw.iloc[0]) * 100

        full_analysis = analyze_sector_performance(prices_raw)
        mdd_value = full_analysis['MDD (%)']
        drawdown_series = full_analysis['drawdown_series']

        trough_date = drawdown_series.idxmin()
        rolling_max_raw = prices_raw.expanding().max()
        peak_price_raw_at_trough = rolling_max_raw.loc[trough_date]
        potential_peak_dates = rolling_max_raw.index[(rolling_max_raw.index <= trough_date) & (
            rolling_max_raw == peak_price_raw_at_trough)]
        peak_date = potential_peak_dates.max()
        peak_price_norm = prices_norm.loc[peak_date]

        # ì°¨íŠ¸ ê·¸ë¦¬ê¸°
        plt.figure(figsize=(10, 6))
        plt.style.use('seaborn-v0_8-whitegrid')

        plt.plot(prices_norm.index, prices_norm.values,
                 label=f'{corp_name} ({ticker})', color='blue')
        plt.scatter(peak_date, peak_price_norm, color='green',
                    marker='o', s=80, label='Peak')
        plt.scatter(trough_date, prices_norm.loc[trough_date],
                    color='red', marker='o', s=80, label='Trough')

        plt.annotate(
            f'MDD: {mdd_value}%',
            (trough_date, prices_norm.loc[trough_date]),
            textcoords="offset points",
            xytext=(0, -20),
            ha='center',
            fontsize=11,
            color='red',
            bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.6)
        )

        plt.title(
            f'Price Movement: {corp_name} ({ticker}) | Event: {event_name}', fontsize=14)
        plt.xlabel('Date', fontsize=10)
        plt.ylabel('Normalized Price (Start=100)', fontsize=10)
        plt.axvline(x=event_date_dt, color='gray', linestyle='--',
                    linewidth=1, label='Event Date')
        plt.axhline(y=100, color='gray', linestyle=':', linewidth=1)
        plt.legend(loc='upper left')
        plt.grid(True)

        buffer = BytesIO()
        plt.savefig(buffer, format='png', bbox_inches='tight')
        plt.close()
        chart_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

        # ê²°ê³¼ DataFrame ìƒì„±
        df_result = pd.DataFrame([analysis])
        df_result.rename(columns={'Final Return (%)': 'Return (%)',
                         'Final DD (%)': 'Final Drawdown (%)'}, inplace=True)
        df_result = df_result[['MDD (%)', 'Return (%)', 'Final Drawdown (%)']]
        df_result.index = [corp_name]

        return {
            'chart_base64': chart_base64,
            'table_html': df_result.to_html(classes='table table-striped', float_format='%.2f'),
            'mdd_value': mdd_value,
            'event_date': event_date_str,
            'corp_name': corp_name,
            'event_name': event_name
        }

    except Exception as e:
        return {'error': f"Data analysis failed: {str(e)}"}


# --- 7. Flask ë¼ìš°íŒ… ì„¤ì • ---

@app.route('/', methods=['GET'])
def index():
    try:
        _, events_by_type = get_disaster_types_and_events()
        disasters_flat = [event for sublist in events_by_type.values()
                          for event in sublist]
    except Exception as e:
        return render_template('index.html', error=str(e), disasters=[])

    return render_template('index.html', disasters=disasters_flat)


@app.route('/analyze', methods=['POST'])
def analyze_web_data():
    event_name = request.form.get('event_name')
    if not event_name:
        return jsonify({'error': 'ì¬ë‚œëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.'}), 400

    analysis_data = run_analysis_for_event(event_name)

    if 'error' in analysis_data:
        return jsonify(analysis_data), 400

    df_html = analysis_data['df_results'].set_index('Sector Name')
    table_html = df_html.to_html(
        classes='table table-striped', float_format='%.2f')

    return jsonify({
        'table_html': table_html,
        'event_name': analysis_data['event_name'],
        'event_date': analysis_data['event_date'],
        'start_date': analysis_data['start_date'],
        'end_date': analysis_data['end_date'],
        'combined_chart_base64': analysis_data['combined_chart'],
        'individual_charts': analysis_data['individual_charts']
    })


@app.route('/individual_analysis', methods=['GET'])
def individual_analysis_page():
    try:
        disaster_types, _ = get_disaster_types_and_events()

    except Exception as e:
        return render_template('individual.html', error=str(e), disaster_types=[])

    return render_template('individual.html', disaster_types=disaster_types)


@app.route('/individual_analysis', methods=['POST'])
def handle_individual_analysis():
    event_name = request.form.get('event_name')
    corp_name = request.form.get('corp_name')

    if not event_name or not corp_name:
        return jsonify({'error': 'ì¬ë‚œ ì´ë¦„ê³¼ íšŒì‚¬ ì´ë¦„ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400

    analysis_result = analyze_individual_stock(event_name, corp_name,
                                               ANALYSIS_MONTHS_BEFORE,
                                               ANALYSIS_MONTHS_AFTER)

    if 'error' in analysis_result:
        return jsonify(analysis_result), 400

    return jsonify({
        'status': 'success',
        'analysis_data': analysis_result
    })

# --- 8. MDD ì˜ˆì¸¡ ë¼ìš°íŠ¸ (ì˜¤ë¥˜ í•´ê²°ë¨) ---


@app.route('/predict_mdd', methods=['GET'])
def predict_mdd_page():
    """MDD ì˜ˆì¸¡ í˜ì´ì§€ ë Œë”ë§"""
    try:
        _, events_by_type = get_disaster_types_and_events()
        # ëª¨ë“  ì¬ë‚œëª…ì„ í‰íƒ„í™”í•˜ì—¬ ë“œë¡­ë‹¤ìš´ì— í‘œì‹œ
        disasters_flat = [event for sublist in events_by_type.values()
                          for event in sublist]
    except Exception as e:
        return render_template('predict_mdd.html', error=str(e), disaster_types=[])

    return render_template('predict_mdd.html', disaster_types=disasters_flat)


@app.route('/predict_mdd', methods=['POST'])
def handle_mdd_prediction():
    """ë‰´ìŠ¤ í¬ë¡¤ë§ -> ë²¡í„° ìƒì„± -> MDD ì˜ˆì¸¡ ì‹¤í–‰"""

    event_name = request.form.get('event_name')

    if not event_name:
        return jsonify({'error': 'ì¬ë‚œëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.'}), 400

    try:
        # **í•µì‹¬: ì™¸ë¶€ ì„œë¹„ìŠ¤ íŒŒì¼ì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë“  ì˜ˆì¸¡ ë¡œì§ ìœ„ì„**
        # ğŸ“Œ ì´ í•¨ìˆ˜ ì´ë¦„ì´ mdd_prediction_service.pyì—ì„œ ì •ì˜í•œ ì´ë¦„ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        prediction_data = mdd_prediction_service.get_today_mdd_prediction(
            event_name)

        if 'error' in prediction_data:
            return jsonify({'error': prediction_data['error']}), 500

        # ì„±ê³µ ì‹œ, ê²°ê³¼ ë°˜í™˜
        return jsonify(prediction_data)

    except Exception as e:
        print(f"MDD ì˜ˆì¸¡ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
        return jsonify({'error': f"MDD ì˜ˆì¸¡ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500


# --- 9. API ì—”ë“œí¬ì¸íŠ¸ ---
@app.route('/api/types', methods=['GET'])
def get_disaster_types():
    """API: ì¬ë‚œ ì¢…ë¥˜(EventType) ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        disaster_types, _ = get_disaster_types_and_events()
        return jsonify({'types': disaster_types})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/events_by_type/<type_name>', methods=['GET'])
def get_events_by_type(type_name):
    """API: ì„ íƒëœ ì¢…ë¥˜(EventType)ì— í•´ë‹¹í•˜ëŠ” ì¬ë‚œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        _, events_by_type = get_disaster_types_and_events()

        type_name = unquote(type_name)

        events = events_by_type.get(type_name, [])
        return jsonify({'events': events})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analyze/<event_name>', methods=['GET'])
def api_analyze_data(event_name):
    """API: ì„¹í„° ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    analysis_data = run_analysis_for_event(event_name)

    if 'error' in analysis_data:
        return jsonify(analysis_data), 400

    df_results = analysis_data['df_results'].reset_index()

    response_data = {
        'event_name': analysis_data['event_name'],
        'event_date': analysis_data['event_date'],
        'analysis_period': f"Start:{analysis_data['start_date']} End:{analysis_data['end_date']}",
        'sector_results': df_results.to_dict(orient='records'),
        'charts': {
            'combined_chart_base64': analysis_data['combined_chart'],
            'individual_charts': analysis_data['individual_charts']
        }
    }

    return jsonify(response_data)


if __name__ == '__main__':
    # ì„œë²„ ì‹œì‘ ì „ ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹œë„
    try:
        # ğŸ“Œ mdd_predictor.pyì—ì„œ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ (mdd_prediction_service ë‚´ë¶€ì—ì„œ ì²˜ë¦¬)
        # ì´ ì‹œì ì—ì„œ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨ ì‹œ, ì—ëŸ¬ê°€ ë°œìƒí•˜ë©° ë°”ë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤.
        pass
    except Exception as e:
        # ì´ ë¶€ë¶„ì€ í˜„ì¬ êµ¬ì¡°ìƒ mdd_prediction_service.py ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
        pass

    app.run(debug=True)
