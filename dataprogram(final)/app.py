import pandas as pd
import numpy as np
from pykrx import stock
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
import os
from flask import Flask, render_template, request, jsonify
from io import BytesIO
import base64
from urllib.parse import unquote
import sys
import mdd_prediction_service  # ğŸ“Œ MDD ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸
import matplotlib.font_manager as fm

# ---------------------------------------------------
plt.switch_backend('Agg')
# ---------------------------------------------------
import platform
from matplotlib import font_manager, rc

def set_korean_font():
    """ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ì „ì— í˜¸ì¶œí•˜ì—¬ í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    # 1. ìš´ì˜ì²´ì œë³„ ê¸°ë³¸ í•œê¸€ í°íŠ¸ ì„¤ì •
    system_name = platform.system()
    
    if system_name == 'Windows':
        # ìœˆë„ìš° ì‚¬ìš©ìëŠ” 'ë§‘ì€ ê³ ë”•' (ê°€ì¥ í™•ì‹¤í•¨)
        rc('font', family='Malgun Gothic')
    elif system_name == 'Darwin':
        # ë§¥ ì‚¬ìš©ìëŠ” 'AppleGothic'
        rc('font', family='AppleGothic')
    else:
        # ë¦¬ëˆ…ìŠ¤ ë“±ì€ ë‚˜ëˆ”ê¸€ê¼´ ì‹œë„
        rc('font', family='NanumGothic')

    # 2. ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
    rc('axes', unicode_minus=False)

# --- Flask ì•± ì´ˆê¸°í™” ---
app = Flask(__name__)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FONT_PATH = os.path.join(BASE_DIR, 'NanumGothic.ttf')

if os.path.exists(FONT_PATH):
    fm.fontManager.addfont(FONT_PATH)
    font_name = fm.FontProperties(fname=FONT_PATH).get_name()
    plt.rcParams['font.family'] = font_name
else:
    # í°íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´, ìœˆë„ìš°ë¼ë©´ ë§êµ¿ê³ ë”• ê°™ì€ ê±¸ ì‹œë„
    plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False

# --- ì„¤ì •ê°’ ë° ìƒìˆ˜ ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DISASTER_CSV_PATH = os.path.join(BASE_DIR, 'event.csv')
ANALYSIS_MONTHS_BEFORE = 3
ANALYSIS_MONTHS_AFTER = 3

# KOSPI 200 Big Sector Index Codes (ì´ 12ê°œ)
SECTOR_CODES = {
    'ì½”ìŠ¤í”¼ ì „ì²´ ì‹œì¥': '1001',
    'ì½”ìŠ¤í”¼200 í†µì‹ ì„œë¹„ìŠ¤': '1150',
    'ì½”ìŠ¤í”¼200 ê±´ì„¤': '1151',
    'ì½”ìŠ¤í”¼200 ì¤‘ê³µì—…': '1152',
    'ì½”ìŠ¤í”¼200 ì² ê°•Â·ì†Œì¬': '1153',
    'ì½”ìŠ¤í”¼200 ì—ë„ˆì§€Â·í™”í•™': '1154',
    'ì½”ìŠ¤í”¼200 ì •ë³´ê¸°ìˆ ': '1155',
    'ì½”ìŠ¤í”¼200 ê¸ˆìœµ': '1156',
    'ì½”ìŠ¤í”¼200 í•„ìˆ˜ì†Œë¹„ì¬': '1157',
    'ì½”ìŠ¤í”¼200 ììœ ì†Œë¹„ì¬': '1158',
    'ì½”ìŠ¤í”¼200 ì‚°ì—…ì¬': '1159',
    'ì½”ìŠ¤í”¼200 í—¬ìŠ¤ì¼€ì–´': '1160'
}

# í™ˆí™”ë©´ ì£¼ê°€ì§€ìˆ˜ ìœ„ì ¯
MAIN_INDEX_CODES = {
    'KOSPI': '1001',
    'KOSDAQ': '2001',
    'KOSPI 200': '1028',
}

from datetime import datetime, timedelta

def get_recent_index_quote(code, name):
    """ìµœê·¼ ë©°ì¹  ê°„ ë°ì´í„° ì¤‘ ë§ˆì§€ë§‰ ê±°ë˜ì¼ ê¸°ì¤€ ì‹œê°€/ì¢…ê°€/ë“±ë½ë¥  ê³„ì‚°"""
    end = datetime.today()
    start = end - timedelta(days=10)

    start_str = start.strftime('%Y%m%d')
    end_str = end.strftime('%Y%m%d')

    df = stock.get_index_ohlcv_by_date(start_str, end_str, code)

    if df.empty:
        raise ValueError(f"{name} ì§€ìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    last = df.iloc[-1]
    close = float(last['ì¢…ê°€'])

    if len(df) > 1:
        prev_close = float(df.iloc[-2]['ì¢…ê°€'])
        change = close - prev_close
        change_pct = (change / prev_close) * 100
    else:
        change = 0.0
        change_pct = 0.0

    return {
        "name": name,
        "close": round(close, 2),
        "change": round(change, 2),
        "change_pct": round(change_pct, 2),
    }
# í™ˆ í™”ë©´ ë

# --- 1. ë¶„ì„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ---


def analyze_sector_performance(close_prices: pd.Series) -> dict:
    """ì£¼ê°€ ë°ì´í„°(ì¢…ê°€ Series)ë¥¼ ë°›ì•„ MDD, ìµœì¢… ì¦ê°ë¥ , Final Drawdownì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    rolling_max = close_prices.expanding().max()
    drawdown = (close_prices / rolling_max) - 1
    mdd_value = round(drawdown.min() * -1 * 100, 2)
    cumulative_return = (close_prices.iloc[-1] / close_prices.iloc[0]) - 1
    cumulative_return_pct = round(cumulative_return * 100, 2)
    final_dd_pct = round(drawdown.iloc[-1] * 100, 2)

    return {
        'MDD (%)': mdd_value,
        'Final Return (%)': cumulative_return_pct,
        'Final DD (%)': final_dd_pct,
        'drawdown_series': drawdown
    }


# --- 2. CSV íŒŒì¼ ë¡œë“œ ë° ê²€ìƒ‰ í•¨ìˆ˜ ---
EXPECTED_COLUMNS = ['EventName', 'EventDate', 'EventType']


def load_csv_with_encoding_fallback():
    """ì—¬ëŸ¬ ì¸ì½”ë”©ì„ ì‹œë„í•˜ê³ , ì‹¤íŒ¨ ì‹œ í—¤ë”ë¥¼ ìˆ˜ë™ ë³µêµ¬í•˜ì—¬ DataFrameì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    df_disaster = None

    for encoding in ['utf-8', 'euc-kr', 'cp949']:
        try:
            df_disaster = pd.read_csv(DISASTER_CSV_PATH, encoding=encoding)
            df_disaster.encoding = encoding
            break
        except Exception:
            continue

    if df_disaster is None:
        raise Exception("CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¸ì½”ë”©ì´ê±°ë‚˜ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")

    if not all(col in df_disaster.columns for col in EXPECTED_COLUMNS):

        try:
            df_disaster_noheader = pd.read_csv(
                DISASTER_CSV_PATH, header=None, encoding=df_disaster.encoding)

            header_row = df_disaster_noheader.iloc[0]
            df_disaster = df_disaster_noheader[1:].copy()
            df_disaster.columns = header_row.tolist()

            if df_disaster.columns.tolist()[:len(EXPECTED_COLUMNS)] != EXPECTED_COLUMNS:
                df_disaster.columns = EXPECTED_COLUMNS + \
                    df_disaster.columns.tolist()[len(EXPECTED_COLUMNS):]

        except Exception as e:
            raise ValueError(
                f"í•„ìˆ˜ ì»¬ëŸ¼ [{', '.join(EXPECTED_COLUMNS)}]ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {df_disaster.columns.tolist()}")

    return df_disaster[EXPECTED_COLUMNS].drop_duplicates()


def get_disaster_types_and_events():
    """CSV íŒŒì¼ì—ì„œ ëª¨ë“  ì¬ë‚œ ì¢…ë¥˜(EventType)ì™€ ì´ë²¤íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    df_disaster = load_csv_with_encoding_fallback()

    disaster_types = sorted(df_disaster['EventType'].unique().tolist())
    events_by_type = df_disaster.groupby('EventType')['EventName'].unique().apply(
        lambda x: sorted(x.tolist())).to_dict()

    return disaster_types, events_by_type


def get_all_disaster_names():
    """CSV íŒŒì¼ì—ì„œ ëª¨ë“  ì¬ë‚œëª…ì„ í‰ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
    df_disaster = load_csv_with_encoding_fallback()

    return df_disaster[['EventName']].drop_duplicates()


def get_event_date_by_name(disaster_name: str) -> str:
    """íŠ¹ì • ì¬ë‚œì˜ ë‚ ì§œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    df_disaster = load_csv_with_encoding_fallback()

    result = df_disaster[df_disaster['EventName'] == disaster_name]
    if result.empty:
        raise ValueError(f"'{disaster_name}'ì— í•´ë‹¹í•˜ëŠ” ì¬ë‚œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    event_datetime_str = result['EventDate'].iloc[0]
    return pd.to_datetime(event_datetime_str).strftime('%Y-%m-%d')


def find_stock_code(corp_name):
    """íšŒì‚¬ ì´ë¦„(ì¢…ëª©ëª…)ìœ¼ë¡œ 6ìë¦¬ ì¢…ëª© ì½”ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        df_list = stock.get_market_ticker_list()
        for ticker in df_list:
            name = stock.get_market_ticker_name(ticker)
            if name == corp_name:
                return ticker
        return None
    except Exception:
        return None

# --- 3. í•µì‹¬ ë¶„ì„ ì‹¤í–‰ ë¡œì§ (ì„¹í„° ì „ì²´) ---


def run_analysis_for_event(event_name):
    """íŠ¹ì • ì¬ë‚œëª…ì— ëŒ€í•œ ì„¹í„° ë¶„ì„ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ DataFrameê³¼ Base64 ì°¨íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""

    try:
        EVENT_DATE_STR = get_event_date_by_name(event_name)
        event_date_dt = pd.to_datetime(EVENT_DATE_STR)

        start_date = (
            event_date_dt - pd.DateOffset(months=ANALYSIS_MONTHS_BEFORE)).strftime('%Y%m%d')
        end_date = (
            event_date_dt + pd.DateOffset(months=ANALYSIS_MONTHS_AFTER)).strftime('%Y%m%d')

    except Exception as e:
        return {'error': str(e)}

    results_list = []
    all_sector_prices = {}
    all_sector_analysis = {}

    for sector_name, code in SECTOR_CODES.items():
        try:
            df_ohlcv = stock.get_index_ohlcv_by_date(
                start_date, end_date, code)

            if df_ohlcv.empty:
                continue

            df_ohlcv.rename(columns={'ì¢…ê°€': 'Close'}, inplace=True)

            analysis = analyze_sector_performance(df_ohlcv['Close'])

            start_price = df_ohlcv['Close'].iloc[0]
            prices_norm = (df_ohlcv['Close'] / start_price) * 100
            all_sector_prices[sector_name] = prices_norm
            all_sector_analysis[sector_name] = {
                'prices': df_ohlcv['Close'], 'mdd_info': analysis}

            results_list.append({
                'Sector Name': sector_name,
                'MDD (%)': analysis['MDD (%)'],
                'Final DD (%)': analysis['Final DD (%)'],
                'Final Return (%)': analysis['Final Return (%)'],
            })

        except Exception:
            continue

    df_results = pd.DataFrame(results_list)

    if df_results.empty:
        return {'error': "ë¶„ì„ ê¸°ê°„ ë™ì•ˆ ìœ íš¨í•œ ì£¼ì‹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    df_results = df_results.sort_values(by='MDD (%)', ascending=False)

    target_name = 'ì½”ìŠ¤í”¼ ì „ì²´ ì‹œì¥'
    
    if target_name in df_results['Sector Name'].values:
        target_row = df_results[df_results['Sector Name'] == target_name]
        rest_rows = df_results[df_results['Sector Name'] != target_name]
        
        df_results = pd.concat([rest_rows, target_row], ignore_index=True)

    # --- 4. ê·¸ë˜í”„ ìƒì„± ë° Base64 ì¸ì½”ë”© ë¡œì§ ---

    # 4-1. í†µí•© ë¹„êµ ì°¨íŠ¸ ìƒì„± (Base64)
    plt.figure(figsize=(15, 8))

    plt.style.use('seaborn-v0_8-whitegrid')
    set_korean_font()

    for sector_name, prices in all_sector_prices.items():
        plt.plot(prices.index, prices.values, label=sector_name)
    plt.title(
        f'Sector Price Movement Comparison (Normalized: Start=100) \n Event Date: {EVENT_DATE_STR}', fontsize=16)
    plt.xlabel('Date', fontsize=12)
    plt.ylabel('Normalized Stock Index', fontsize=12)
    plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title='Sector')
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))
    plt.gcf().autofmt_xdate()
    plt.axvline(x=event_date_dt, color='red', linestyle='-',
                linewidth=2, label='Event Date')
    plt.axhline(y=100, color='gray', linestyle='--', linewidth=1)
    plt.grid(True)

    buffer = BytesIO()
    plt.savefig(buffer, format='png', bbox_inches='tight')
    plt.close()
    combined_chart_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

    # 4-2. ê°œë³„ ì„¹í„° ì°¨íŠ¸ ìƒì„± (Base64 ë¦¬ìŠ¤íŠ¸)
    individual_charts = []
    for sector_name, analysis_data in all_sector_analysis.items():
        prices_norm = all_sector_prices[sector_name]
        prices_raw = analysis_data['prices']
        full_analysis = analyze_sector_performance(prices_raw)
        mdd_value = full_analysis['MDD (%)']
        drawdown_series = full_analysis['drawdown_series']

        trough_date = drawdown_series.idxmin()
        rolling_max_raw = prices_raw.expanding().max()
        peak_price_raw_at_trough = rolling_max_raw.loc[trough_date]
        potential_peak_dates = rolling_max_raw.index[(rolling_max_raw.index <= trough_date) & (
            rolling_max_raw == peak_price_raw_at_trough)]
        peak_date = potential_peak_dates.max()
        peak_price_norm = prices_norm.loc[peak_date]

        # ì°¨íŠ¸ ê·¸ë¦¬ê¸°
        plt.figure(figsize=(10, 6))

        plt.style.use('seaborn-v0_8-whitegrid')
        set_korean_font()

        plt.plot(prices_norm.index, prices_norm.values,
                 label=sector_name, color='blue')
        plt.scatter(peak_date, peak_price_norm, color='green',
                    marker='o', s=80, label='Peak')
        plt.scatter(trough_date, prices_norm.loc[trough_date],
                    color='red', marker='o', s=80, label='Trough')
        plt.annotate(f'MDD: {mdd_value}%', (trough_date, prices_norm.loc[trough_date]), textcoords="offset points", xytext=(
            0, -20), ha='center', fontsize=11, color='red', bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.6))
        plt.title(
            f'Price Movement: {sector_name} (MDD: {mdd_value}%)', fontsize=14)
        plt.xlabel('Date', fontsize=10)
        plt.ylabel('Normalized Stock Index (Start=100)', fontsize=10)
        plt.axvline(x=event_date_dt, color='gray', linestyle='--',
                    linewidth=1, label='Event Date')
        plt.axhline(y=100, color='gray', linestyle=':', linewidth=1)
        plt.legend(loc='upper left')
        plt.grid(True)

        buffer = BytesIO()
        plt.savefig(buffer, format='png', bbox_inches='tight')
        plt.close()
        individual_charts.append({
            'name': sector_name,
            'base64_img': base64.b64encode(buffer.getvalue()).decode('utf-8')
        })

    # --- 5. ìµœì¢… ë°˜í™˜ ---
    return {
        'df_results': df_results,
        'event_name': event_name,
        'event_date': event_date_dt.strftime('%Y-%m-%d'),
        'start_date': start_date,
        'end_date': end_date,
        'combined_chart': combined_chart_base64,
        'individual_charts': individual_charts
    }

# --- 6. ê°œë³„ ê¸°ì—… ë¶„ì„ ë¡œì§ ---


def analyze_individual_stock(event_name, corp_name, months_before, months_after):
    """ê°œë³„ ì¢…ëª©ì˜ MDDì™€ ì°¨íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""

    try:
        event_date_str = get_event_date_by_name(event_name)
        event_date_dt = pd.to_datetime(event_date_str)

        ticker = find_stock_code(corp_name)

        if not ticker:
            raise ValueError(f"'{corp_name}' ticker not found.")

        start_date = (event_date_dt -
                      pd.DateOffset(months=months_before)).strftime('%Y%m%d')
        end_date = (event_date_dt +
                    pd.DateOffset(months=months_after)).strftime('%Y%m%d')

        df_ohlcv = stock.get_market_ohlcv_by_date(start_date, end_date, ticker)

        if df_ohlcv.empty:
            raise ValueError(
                f"No data available for '{corp_name}' in the period.")

        df_ohlcv.rename(columns={'ì¢…ê°€': 'Close'}, inplace=True)

        analysis = analyze_sector_performance(df_ohlcv['Close'])

        # --- ì°¨íŠ¸ ìƒì„± ë¡œì§ ---

        prices_raw = df_ohlcv['Close']
        prices_norm = (prices_raw / prices_raw.iloc[0]) * 100

        full_analysis = analyze_sector_performance(prices_raw)
        mdd_value = full_analysis['MDD (%)']
        drawdown_series = full_analysis['drawdown_series']

        trough_date = drawdown_series.idxmin()
        rolling_max_raw = prices_raw.expanding().max()
        peak_price_raw_at_trough = rolling_max_raw.loc[trough_date]
        potential_peak_dates = rolling_max_raw.index[(rolling_max_raw.index <= trough_date) & (
            rolling_max_raw == peak_price_raw_at_trough)]
        peak_date = potential_peak_dates.max()
        peak_price_norm = prices_norm.loc[peak_date]

        # ì°¨íŠ¸ ê·¸ë¦¬ê¸°
        plt.figure(figsize=(10, 6))
        plt.style.use('seaborn-v0_8-whitegrid')
        set_korean_font()

        plt.plot(prices_norm.index, prices_norm.values,
                 label=f'{corp_name} ({ticker})', color='blue')
        plt.scatter(peak_date, peak_price_norm, color='green',
                    marker='o', s=80, label='Peak')
        plt.scatter(trough_date, prices_norm.loc[trough_date],
                    color='red', marker='o', s=80, label='Trough')

        plt.annotate(
            f'MDD: {mdd_value}%',
            (trough_date, prices_norm.loc[trough_date]),
            textcoords="offset points",
            xytext=(0, -20),
            ha='center',
            fontsize=11,
            color='red',
            bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.6)
        )

        plt.title(
            f'Price Movement: {corp_name} ({ticker}) | Event: {event_name}', fontsize=14)
        plt.xlabel('Date', fontsize=10)
        plt.ylabel('Normalized Price (Start=100)', fontsize=10)
        plt.axvline(x=event_date_dt, color='gray', linestyle='--',
                    linewidth=1, label='Event Date')
        plt.axhline(y=100, color='gray', linestyle=':', linewidth=1)
        plt.legend(loc='upper left')
        plt.grid(True)

        buffer = BytesIO()
        plt.savefig(buffer, format='png', bbox_inches='tight')
        plt.close()
        chart_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

        # ê²°ê³¼ DataFrame ìƒì„±
        df_result = pd.DataFrame([analysis])
        df_result.rename(columns={'Final Return (%)': 'Return (%)',
                         'Final DD (%)': 'Final Drawdown (%)'}, inplace=True)
        df_result = df_result[['MDD (%)', 'Return (%)', 'Final Drawdown (%)']]
        df_result.index = [corp_name]

        return {
            'chart_base64': chart_base64,
            'table_html': df_result.to_html(classes='table table-striped', float_format='%.2f'),
            'mdd_value': mdd_value,
            'event_date': event_date_str,
            'corp_name': corp_name,
            'event_name': event_name
        }

    except Exception as e:
        return {'error': f"Data analysis failed: {str(e)}"}


# --- 7. Flask ë¼ìš°íŒ… ì„¤ì • ---

@app.route('/api/disaster_news', methods=['GET'])
def api_disaster_news():
    try:
        news_grouped = mdd_prediction_service.get_today_disaster_news_grouped(max_results=3)
        return jsonify({'status': 'success', 'news': news_grouped})
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500
    
@app.route('/api/main_indices', methods=['GET'])
def api_main_indices():
    # í™ˆ í™”ë©´ ì˜¤ë¥¸ìª½ ì‚¬ì´ë“œì— ë³´ì—¬ì¤„ ì£¼ìš” ì§€ìˆ˜ ì •ë³´
    indices = []
    for name, code in MAIN_INDEX_CODES.items():
        try:
            info = get_recent_index_quote(code, name)
            indices.append(info)
        except Exception as e:
            # í•˜ë‚˜ ì‹¤íŒ¨í•´ë„ ë‚˜ë¨¸ì§€ëŠ” ë³´ì—¬ì£¼ê¸°
            continue

    if not indices:
        return jsonify({'status': 'error', 'error': 'ì§€ìˆ˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'}), 500

    return jsonify({'status': 'success', 'indices': indices})

@app.route('/api/sector_changes', methods=['GET'])
def api_sector_changes():
    # KOSPI 200 ì„¹í„°ë³„ ë“±ë½ë¥  ìœ„ì ¯ìš© ë°ì´í„°
    sectors = []
    for name, code in SECTOR_CODES.items():
        try:
            info = get_recent_index_quote(code, name)  # close, change, change_pct
            sectors.append(info)
        except Exception:
            continue

    if not sectors:
        return jsonify({'status': 'error', 'error': 'ì„¹í„° ì§€ìˆ˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'}), 500

    # ë“±ë½ë¥  ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    sectors_sorted = sorted(sectors, key=lambda x: x['change_pct'], reverse=True)

    return jsonify({'status': 'success', 'sectors': sectors_sorted})



@app.route('/', methods=['GET'])
def home_page():
    return render_template('home.html')

@app.route('/sector', methods=['GET'])
def sector_page():
    try:
        _, events_by_type = get_disaster_types_and_events()
        disasters_flat = [event for sublist in events_by_type.values()
                          for event in sublist]
    except Exception as e:
        return render_template('index.html', error=str(e), disasters=[])

    return render_template('index.html', disasters=disasters_flat)


@app.route('/analyze', methods=['POST'])
def analyze_web_data():
    event_name = request.form.get('event_name')
    if not event_name:
        return jsonify({'error': 'ì¬ë‚œëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.'}), 400

    analysis_data = run_analysis_for_event(event_name)

    if 'error' in analysis_data:
        return jsonify(analysis_data), 400

    # 1) í…Œì´ë¸”ìš© HTML
    df_results = analysis_data['df_results']   # ì»¬ëŸ¼: Sector Name, MDD (%), Final DD (%), Final Return (%)
    df_html = df_results.set_index('Sector Name')
    table_html = df_html.to_html(
        classes='table table-striped', float_format='%.2f')

    # 2) íˆíŠ¸ë§µìš© JSON ë°ì´í„°
    sector_results = df_results.to_dict(orient='records')

    return jsonify({
        'table_html': table_html,
        'event_name': analysis_data['event_name'],
        'event_date': analysis_data['event_date'],
        'start_date': analysis_data['start_date'],
        'end_date': analysis_data['end_date'],
        'combined_chart_base64': analysis_data['combined_chart'],
        'individual_charts': analysis_data['individual_charts'],
        'sector_results': sector_results      # âœ… ì¶”ê°€ëœ ë¶€ë¶„
    })



@app.route('/individual_analysis', methods=['GET'])
def individual_analysis_page():
    try:
        disaster_types, _ = get_disaster_types_and_events()

    except Exception as e:
        return render_template('individual.html', error=str(e), disaster_types=[])

    return render_template('individual.html', disaster_types=disaster_types)


@app.route('/individual_analysis', methods=['POST'])
def handle_individual_analysis():
    event_name = request.form.get('event_name')
    corp_name = request.form.get('corp_name')

    if not event_name or not corp_name:
        return jsonify({'error': 'ì¬ë‚œ ì´ë¦„ê³¼ íšŒì‚¬ ì´ë¦„ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400

    # 1. ê°œë³„ ì¢…ëª© ë¶„ì„ (ê¸°ì¡´ ë¡œì§)
    analysis_result = analyze_individual_stock(event_name, corp_name,
                                               ANALYSIS_MONTHS_BEFORE,
                                               ANALYSIS_MONTHS_AFTER)

    if 'error' in analysis_result:
        return jsonify(analysis_result), 400
    
    # ---------------------------------------------------------
    # 2. [ì¶”ê°€ë¨] ì‚¬ì´ë“œë°”ìš© TOP5 ë°ì´í„° ìƒì„± (ì„¹í„° ë°ì´í„° í™œìš©)
    # ---------------------------------------------------------
    top_gainers = []
    top_losers = []

    try:
        # ì „ì²´ ì‹œì¥(ì„¹í„°) íë¦„ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©
        sector_data = run_analysis_for_event(event_name)
        
        if 'df_results' in sector_data and not sector_data['df_results'].empty:
            df = sector_data['df_results']  # ì»¬ëŸ¼: Sector Name, Final Return (%), ...
            
            # ìˆ˜ìµë¥  ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            df_sorted = df.sort_values(by='Final Return (%)', ascending=False)

            # ìƒìœ„ 5ê°œ (Gainers)
            for _, row in df_sorted.head(5).iterrows():
                top_gainers.append({
                    'name': row['Sector Name'],
                    'change_pct': row['Final Return (%)']
                })

            # í•˜ìœ„ 5ê°œ (Losers) - ë’¤ì—ì„œ 5ê°œë¥¼ ë½‘ì•„ ë‹¤ì‹œ ì˜¤ë¦„ì°¨ìˆœ(í° í•˜ë½í­ ë¨¼ì €) ì •ë ¬
            for _, row in df_sorted.tail(5).sort_values(by='Final Return (%)', ascending=True).iterrows():
                top_losers.append({
                    'name': row['Sector Name'],
                    'change_pct': row['Final Return (%)']
                })
                
    except Exception as e:
        # ì‚¬ì´ë“œë°” ë°ì´í„° ìƒì„± ì‹¤íŒ¨í•´ë„ ë©”ì¸ ë¶„ì„ì€ ë³´ì—¬ì£¼ê¸° ìœ„í•´ pass
        print(f"Top list generation failed: {e}")
        pass

    # 3. ìµœì¢… ë°˜í™˜ (top_gainers, top_losers ì¶”ê°€)
    return jsonify({
        'status': 'success',
        'analysis_data': analysis_result,
        'top_gainers': top_gainers,
        'top_losers': top_losers
    })

# --- 8. MDD ì˜ˆì¸¡ ë¼ìš°íŠ¸ (ì˜¤ë¥˜ í•´ê²°ë¨) ---


@app.route('/predict_mdd', methods=['GET'])
def predict_mdd_page():
    """MDD ì˜ˆì¸¡ í˜ì´ì§€ ë Œë”ë§"""
    try:
        _, events_by_type = get_disaster_types_and_events()
        # ëª¨ë“  ì¬ë‚œëª…ì„ í‰íƒ„í™”í•˜ì—¬ ë“œë¡­ë‹¤ìš´ì— í‘œì‹œ
        disasters_flat = [event for sublist in events_by_type.values()
                          for event in sublist]
    except Exception as e:
        return render_template('predict_mdd.html', error=str(e), disaster_types=[])

    return render_template('predict_mdd.html', disaster_types=disasters_flat)


@app.route('/predict_mdd', methods=['POST'])
def handle_mdd_prediction():
    """ë‰´ìŠ¤ í¬ë¡¤ë§ -> ë²¡í„° ìƒì„± -> MDD ì˜ˆì¸¡ ì‹¤í–‰"""

    event_name = request.form.get('event_name')

    if not event_name:
        return jsonify({'error': 'ì¬ë‚œëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.'}), 400

    try:
        # **í•µì‹¬: ì™¸ë¶€ ì„œë¹„ìŠ¤ íŒŒì¼ì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë“  ì˜ˆì¸¡ ë¡œì§ ìœ„ì„**
        # ğŸ“Œ ì´ í•¨ìˆ˜ ì´ë¦„ì´ mdd_prediction_service.pyì—ì„œ ì •ì˜í•œ ì´ë¦„ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        prediction_data = mdd_prediction_service.get_today_mdd_prediction(
            event_name)

        if 'error' in prediction_data:
            return jsonify({'error': prediction_data['error']}), 500

        # ì„±ê³µ ì‹œ, ê²°ê³¼ ë°˜í™˜
        return jsonify(prediction_data)

    except Exception as e:
        print(f"MDD ì˜ˆì¸¡ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
        return jsonify({'error': f"MDD ì˜ˆì¸¡ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500


# --- 9. API ì—”ë“œí¬ì¸íŠ¸ ---
@app.route('/api/types', methods=['GET'])
def get_disaster_types():
    """API: ì¬ë‚œ ì¢…ë¥˜(EventType) ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        disaster_types, _ = get_disaster_types_and_events()
        return jsonify({'types': disaster_types})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/events_by_type/<type_name>', methods=['GET'])
def get_events_by_type(type_name):
    """API: ì„ íƒëœ ì¢…ë¥˜(EventType)ì— í•´ë‹¹í•˜ëŠ” ì¬ë‚œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        _, events_by_type = get_disaster_types_and_events()

        type_name = unquote(type_name)

        events = events_by_type.get(type_name, [])
        return jsonify({'events': events})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analyze/<event_name>', methods=['GET'])
def api_analyze_data(event_name):
    """API: ì„¹í„° ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    analysis_data = run_analysis_for_event(event_name)

    if 'error' in analysis_data:
        return jsonify(analysis_data), 400

    df_results = analysis_data['df_results'].reset_index()

    response_data = {
        'event_name': analysis_data['event_name'],
        'event_date': analysis_data['event_date'],
        'analysis_period': f"Start:{analysis_data['start_date']} End:{analysis_data['end_date']}",
        'sector_results': df_results.to_dict(orient='records'),
        'charts': {
            'combined_chart_base64': analysis_data['combined_chart'],
            'individual_charts': analysis_data['individual_charts']
        }
    }

    return jsonify(response_data)


if __name__ == '__main__':
    # ì„œë²„ ì‹œì‘ ì „ ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹œë„
    try:
        # ğŸ“Œ mdd_predictor.pyì—ì„œ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ (mdd_prediction_service ë‚´ë¶€ì—ì„œ ì²˜ë¦¬)
        # ì´ ì‹œì ì—ì„œ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨ ì‹œ, ì—ëŸ¬ê°€ ë°œìƒí•˜ë©° ë°”ë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤.
        pass
    except Exception as e:
        # ì´ ë¶€ë¶„ì€ í˜„ì¬ êµ¬ì¡°ìƒ mdd_prediction_service.py ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
        pass

    app.run(debug=True)
